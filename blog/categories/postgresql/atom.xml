<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: postgresql | Manuel van Rijn]]></title>
  <link href="http://manuel.manuelles.nl/blog/categories/postgresql/atom.xml" rel="self"/>
  <link href="http://manuel.manuelles.nl/"/>
  <updated>2012-07-30T10:47:48+02:00</updated>
  <id>http://manuel.manuelles.nl/</id>
  <author>
    <name><![CDATA[Manuel van Rijn]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Taking MemSQL for a spin]]></title>
    <link href="http://manuel.manuelles.nl/blog/2012/06/20/taking-memsql-for-a-spin/"/>
    <updated>2012-06-20T10:18:00+02:00</updated>
    <id>http://manuel.manuelles.nl/blog/2012/06/20/taking-memsql-for-a-spin</id>
    <content type="html"><![CDATA[<p><a href="/blog/2012/06/20/taking-memsql-for-a-spin/"><img class="left" src="/images/posts/memsql.png" width="200" height="200" title="MemSQL" ></a> This week I read an article on <a href="http://news.ycombinator.com/item?id=4126007">HackerNews</a> about Ex-facebook employs releasing a new database server called MemSQL.</p>

<p>After viewing there <a href="http://developers.memsql.com/">product overview video</a> I got excited and wanted to take this product for a spin.</p>

<!-- more -->


<h2>What to test?</h2>

<p>First I needed a project for testing the performance on. At <a href="http://www.auxilium.nl">my work</a> we developed a Rails application that needs to validate a permit request with rules, questions, filters, answers depending on a region etc. etc. This process of validating a whole permit request takes some time because it has to perform <strong>6850 queries</strong>.</p>

<h2>Performance PostgreSQL</h2>

<p>At this moment the application runs on a PostgreSQL database so lets see what the performance is at this point:</p>

<p>```
run       user     system      total        real</p>

<h1>01  10.690000   0.540000  11.230000 ( 14.828312)</h1>

<h1>02   9.450000   0.490000   9.940000 ( 13.895988)</h1>

<h1>03   9.550000   0.470000  10.020000 ( 14.215028)</h1>

<p>```</p>

<p><span class='pullquote-right' data-pullquote='14.312ms for 6850 queries'>
The average result is that it takes 14.312ms for 6850 queries on PostgreSQL.
</span></p>

<h2>Configuring the Rails app to use MemSQL</h2>

<p>After installing MemSQL and starting it running on port 3307, I created a new database added the existing data and changed some connection strings for the Rails app.</p>

<h3>mysql2 gem</h3>

<p>Because MemSQL is built on top of MySQL you can use all the MySQL client tools to perform operations on MemSQL.</p>

<p>The MemSQL documentation recommended using the memsql2 gem but to do this I had to install MySQL first on my machine.</p>

<h3>Failed to connect?</h3>

<p>After installing MySQL and configured the Rails application I got some strange error when starting the application.</p>

<p><code>
Failed to connect to database:
  Sequel::AdapterNotFound -&gt; LoadError: dlopen(.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/mysql2-0.3.11/lib/mysql2/mysql2.bundle, 9): Library not loaded: /usr/local/mysql/lib/libmysqlclient.16.dylib
  Referenced from: /Users/mvanrijn/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/mysql2-0.3.11/lib/mysql2/mysql2.bundle
  Reason: image not found - /Users/mvanrijn/.rbenv/versions/1.9.3-p194/lib/ruby/gems/1.9.1/gems/mysql2-0.3.11/lib/mysql2/mysql2.bundle
</code></p>

<p>After some googling I found out that on OSX you might need to symlink the dylib manually. <strong>NOTE</strong> Because I've installed a newer version of MySQL I have a <code>libmysqlclient.18.dylib</code> instead of the required <code>libmysqlclient.16.dylib</code>. Symlinking this file from libmysqlclient.18.dylib to libmysqlclient.16.dylib seemed to work for me.</p>

<p><code>
sudo ln -s /usr/local/mysql/lib/libmysqlclient.18.dylib /usr/local/mysql/lib/libmysqlclient.16.dylib
</code></p>

<h3>Explain not supported for joins</h3>

<p>At this point I am able to connect to the database and perform the benchmark, but I got the next error:</p>

<p><code>
ActiveRecord::StatementInvalid: Mysql2::Error: Feature 'EXPLAIN for join queries' is not supported by MemSQL.
</code></p>

<p>Apparently I've EXPLAIN queries on in my config and this isn't supported for JOIN queries as MemSQL tells us.</p>

<p>To resolve this you just have to modify/add this line in your <code>config/environment/development.rb</code></p>

<p><code>
config.active_record.auto_explain_threshold_in_seconds = nil
</code></p>

<h2>MemSQL's first spin!</h2>

<p><span class='pullquote-right' data-pullquote='first run took 3 min and 05 seconds!'>
So after resolving all these issues I was able to run the benchmark, but the first run took 3 min and 05 seconds! First I thought that this can not be right, but I forgot the fact that it generate's c code from the queries.
</span></p>

<p>On the MemSQL server I got the following output:</p>

<p><code>``sql
2908919519 2012-06-20 09:56:16 INFO: Query appdb.'SELECT </code>permit_requests<code>.* FROM</code>permit_requests<code> WHERE</code>permit_requests<code>.</code>id<code>= @ LIMIT @' compiled in 7306 milliseconds
2908983637 2012-06-20 09:56:16 WARNING: WARN DISABLED LOCKDOWN: BEGIN TRANSACTION
2916240227 2012-06-20 09:56:23 INFO: Query appdb.'SELECT </code>categories<code>.* FROM</code>categories<code> WHERE</code>categories<code>.</code>id<code>= @ ORDER BY name LIMIT @' compiled in 7203 milliseconds
2924143142 2012-06-20 09:56:31 INFO: Query appdb.'SELECT</code>questions<code>.* FROM</code>questions<code> WHERE</code>questions<code>.</code>category_id` = @ ORDER BY position' compiled in 7722 milliseconds</p>

<p>... etc ...
```</p>

<p>As you can see, generating the compiled version for every query took about 7 seconds.</p>

<h2>Performance MemSQL</h2>

<p>So below again the same table with results. The first line is the time with generating all the compiled queries:</p>

<p>```
run       user     system      total        real</p>

<h1>01   5.260000   0.360000   5.620000 (183.511099)</h1>

<h1>02   3.830000   0.260000   4.090000 (  6.657682)</h1>

<h1>03   3.790000   0.260000   4.050000 (  6.613542)</h1>

<p>```</p>

<p><span class='pullquote-right' data-pullquote='6.635ms for 6850 queries'>
The performance boost is quite huge! The average result is 6.635ms for 6850 queries if we are skipping the first result. This means it's like 7.677ms faster!
</span></p>

<h3>Cold boot of MemSQL</h3>

<p>I've also tried the performance when I restart the database server. I just wanted to know if it keeps the data in memory and would take longer to run after a restart.</p>

<p>The result:</p>

<p>```
run       user     system      total        real</p>

<h1>01   5.110000   0.330000   5.440000 (  8.030930)</h1>

<h1>02   3.770000   0.260000   4.030000 (  6.580312)</h1>

<h1>03   3.780000   0.250000   4.030000 (  6.524884)</h1>

<p>```</p>

<p><span class='pullquote-right' data-pullquote='7.044ms for 6850 queries'>
The first time it took just a bit longer, but with an average of 7.044ms for 6850 queries this is still faster than running it on PostgreSQL!
</span></p>

<h2>Pros and Cons</h2>

<p>Here's a list with some pros and cons I noticed while experimenting with MemSQL:</p>

<h3>Pros</h3>

<ul>
<li>Blazing fast!</li>
<li>You can use all the MySQL client tools out there. Also because it uses MySQL, troubleshooting might not be an issue because it isn't a new product.</li>
</ul>


<h3>Cons</h3>

<ul>
<li>Huge cache folder! After restoring the database (15Mb) MemSQL creates a folder in the <code>plancache</code> folder which is <strong>5.5GB</strong>. So performance comes with a price I think.</li>
<li>Unable to create users. When creating the database, I tried to add a new user but this isn't supported. Maybe this is because I'm using the Developer Edition.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[“Rake, pull me that DB!”]]></title>
    <link href="http://manuel.manuelles.nl/blog/2012/01/19/rake-pull-me-that-db/"/>
    <updated>2012-01-19T15:15:00+01:00</updated>
    <id>http://manuel.manuelles.nl/blog/2012/01/19/rake-pull-me-that-db</id>
    <content type="html"><![CDATA[<p>After writing my last article how to <a href="http://manuel.manuelles.nl/blog/2012/01/18/convert-postgresql-to-sqlite/" title="How to: Convert a PostgreSQL database to a SQLite database">Convert PostgreSQL to SQLite</a>, I was asked why this couldn't be automated?</p>

<p>So I started coding and managed to create a <a href="http://rake.rubyforge.org/" title="Rake -- Ruby Make">Rake</a> task that will do all of the steps I described in the article in just a few seconds!</p>

<!-- more -->


<h2>Update</h2>

<p>Today a found a project that does exactly the samething as the below rake task, but with support for more db providers. <a href="http://www.herko.com">Heroku</a> uses this project for retrieving and pushing you database to the heroku database server.</p>

<p>The project is called Taps and can be found here: <a href="http://adam.heroku.com/past/2009/2/11/taps_for_easy_database_transfers/">http://adam.heroku.com/past/2009/2/11/taps_for_easy_database_transfers</a></p>

<h2>What will it do?</h2>

<ol>
<li>remove old dump and ssh the new dump to <code>tmp/dump.sql</code></li>
<li>converts the dumped SQL in to a valid format for SQLite</li>
<li>remembers the version number of the migration on the production db</li>
<li>backup, create and migrates the development SQLite to the version remembered</li>
<li>import the SQL</li>
<li>tell you all went well</li>
</ol>


<h2>Configuration</h2>

<p>To use the Rake task, you have to add 2 additional fields (<code>ssh_user</code> and <code>ssh_host</code>) to your <code>database.yml</code> file. These fields are used to create an ssh connection for retrieving the PostgreSQL dump.</p>

<p>Here's example of a modified <code>config/database.yml</code>:</p>

<p><div><script src='https://gist.github.com/1640429.js?file=database.yml'></script>
<noscript><pre><code>development:
  adapter: sqlite3
  database: db/development.sqlite3
  pool: 5
  timeout: 5000

production:
  ssh_user: root                  # &lt;-- add username for ssh
  ssh_host: productionserver.com  # &lt;-- add hostname for ssh
  adapter: postgresql
  host: localhost
  port: 5432
  username: db_user
  password: db_pass
  database: db_name
  schema_search_path: public
  encoding: utf8
  template: template0</code></pre></noscript></div>
</p>

<h2>Get the Rake file</h2>

<p>Put the following code into <code>libs/tasks/database.rake</code></p>

<p><div><script src='https://gist.github.com/1640429.js?file=database.rake'></script>
<noscript><pre><code>require 'fileutils'

namespace :db do
  desc 'pull the production PostgreSQL database into the development SQLite'
  task :pull do
    Rake::Task['db:download_pg_dump'].invoke
    Rake::Task['db:optimze_pg_dump_for_sqlite'].invoke
    Rake::Task['db:recreate_with_dump'].invoke
  end

  desc 'download the pg_dump content into tmp/dump.sql'
  task :download_pg_dump do
    config = Rails.application.config.database_configuration

    abort &quot;Missing production database config&quot; if config['production'].blank?

    dev  = config['development']
    prod = config['production']

    abort &quot;Development db is not sqlite3&quot; unless dev['adapter'] =~ /sqlite3/
    abort &quot;Production db is not postgresql&quot; unless prod['adapter'] =~ /postgresql/
    abort &quot;Missing ssh host&quot; if prod['ssh_host'].blank?
    abort &quot;Missing database name&quot; if prod['database'].blank?

    # remove the old one
    if File.exists?(pg_dump_file_path)
      File.delete(pg_dump_file_path)
    end

    cmd  = &quot;ssh -C &quot;
    cmd &lt;&lt; &quot;#{prod['ssh_user']}@&quot; if prod['ssh_user'].present?
    cmd &lt;&lt; &quot;#{prod['ssh_host']} &quot;
    cmd &lt;&lt; &quot;PGPASSWORD=#{prod['password']} &quot;
    cmd &lt;&lt; &quot;pg_dump --data-only --inserts &quot;
    cmd &lt;&lt; &quot;--username=#{prod['username']} #{prod['database']} &gt; &quot;
    cmd &lt;&lt; pg_dump_file_path

    system `#{cmd}`
  end

  desc 'remove unused statements and optimze sql for SQLite'
  task :optimze_pg_dump_for_sqlite do
    result = []
    lines = File.readlines(pg_dump_file_path)
    @version = 0
    lines.each do | line |
      next if line =~ /SELECT pg_catalog.setval/  # sequence value's
      next if line =~ /SET /                      # postgres specific config
      next if line =~ /--/                        # comment

      if line =~ /INSERT INTO schema_migrations/
        @version = line.match(/INSERT INTO schema_migrations VALUES \('([\d]*)/)[1]
      end

      # replace true and false for 't' and 'f'
      line.gsub!(&quot;true&quot;,&quot;'t'&quot;)
      line.gsub!(&quot;false&quot;,&quot;'f'&quot;)
      result &lt;&lt; line
    end

    File.open(pg_dump_file_path, &quot;w&quot;) do |f|
      # Add BEGIN and END so we add it to 1 transaction. Increase speed!
      f.puts(&quot;BEGIN;&quot;)
      result.each{|line| f.puts(line) unless line.blank?}
      f.puts(&quot;END;&quot;)
    end
  end

  desc 'backup development.sqlite3 and create a new one with the dumped data'
  task :recreate_with_dump do
    # sqlite so backup
    database = Rails.configuration.database_configuration['development']['database']
    database_path = File.expand_path(&quot;#{Rails.root}/#{database}&quot;)
    # remove old backup
    if File.exists?(database_path + '.backup')
      File.delete(database_path + '.backup')
    end
    # copy current for backup
    FileUtils.cp database_path, database_path + '.backup' if File.exists?(database_path)

    # dropping and re-creating db
    ENV['VERSION'] = @version
    Rake::Task['db:drop'].invoke
    Rake::Task[&quot;db:migrate&quot;].invoke

    puts &quot;migrated to version: #{@version}&quot;
    puts &quot;importing...&quot;
    # remove migration info
    system `sqlite3 #{database_path} &quot;delete from schema_migrations;&quot;`
    # import dump.sql
    system `sqlite3 #{database_path} &quot;.read #{pg_dump_file_path}&quot;`

    puts &quot;DONE!&quot;
    puts &quot;NOTE: you're now migrated to version #{@version}. Please run db:migrate to apply newer migrations&quot;
  end

  def pg_dump_file_path
    File.expand_path(&quot;#{Rails.root}/tmp/dump.sql&quot;)
  end
end</code></pre></noscript></div>
</p>

<h2>Usage</h2>

<p><code>
bundle exec rake db:pull
</code></p>

<h3>No SSH?</h3>

<p>If you want to skip the step where the rake tasks get's the dump using ssh, you have to copy the dump.sql into the tmp folder by yourself (note that the name <strong>must</strong> be <code>dump.sql</code>)</p>

<p>After you copied it, you should execute the following commands, to generate the development database with the dumped sql.</p>

<p><code>
bundle exec rake db:optimze_pg_dump_for_sqlite
bundle exec rake db:recreate_with_dump
</code></p>

<h3>Want to skip entering the ssh password every time?</h3>

<p>You could generate a public/private key pair with RSA and append that key to the production server so you don't have to enter the password over and over again to connect with ssh.</p>

<h4>1. Generate a public/private key pair with RSA</h4>

<p>First check if you haven't already generated a <code>id_rsa</code> file in your <code>$HOME/.shh</code> folder. If you already have a <code>id_rsa</code> file continue with step 2.</p>

<p>Run the following command on you local machine and accept the defaults.</p>

<p><code>
ssh-keygen -t rsa
</code></p>

<p>This command creates an RSA public/private key pair in your <code>$HOME/.ssh</code> directory. The private key is <code>~/.ssh/id_rsa</code> and the public key is <code>~/.ssh/id_rsa.pub</code></p>

<h4>2. Install public key on remote machine</h4>

<p>Now you can copy the public key to the remote machine by executing the following command:</p>

<p><code>
ssh-copy-id -i root@productionserver.com
</code></p>

<p>This command will ask you to enter the ssh password for the ssh user "root" for the hostname "productionserver.com".</p>

<p>After you've enter the password (for the last time) you can create a ssh connection without entering the password by executing:</p>

<p><code>
ssh root@productionserver.com
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert PostgreSQL to SQLite]]></title>
    <link href="http://manuel.manuelles.nl/blog/2012/01/18/convert-postgresql-to-sqlite/"/>
    <updated>2012-01-18T00:30:00+01:00</updated>
    <id>http://manuel.manuelles.nl/blog/2012/01/18/convert-postgresql-to-sqlite</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/posts/postgres-to-sqlite.png" width="220" height="220" title="Postgres to SQLite" ></p>

<p>Today I'd like to share the steps I take when I need to convert a <a href="http://www.postgresql.org/" title="PostgreSQL">PostgreSQL</a> database into a <a href="http://www.sqlite.org/" title="SQLite">SQLite</a> database.</p>

<p>Commonly I have to do this when a <a href="http://rubyonrails.org/" title="Ruby on Rails">Ruby on Rails</a> application is in production and I have to check some issues with the production data. In the production environment we usually use a PostgreSQL database and for developing I use a SQLite database, so we need some conversion.</p>

<!-- more -->


<h2>Short story a.k.a I know what I'm doing.</h2>

<ol>
<li>Create a dump of the PostgreSQL database.
<code>ssh -C username@hostname.com pg_dump --data-only --inserts YOUR_DB_NAME &gt; dump.sql</code></li>
<li>Remove/modify the dump.

<ul>
<li>Remove the lines starting with <code>SET</code></li>
<li>Remove the lines starting with <code>SELECT pg_catalog.setval</code></li>
<li>Replace true for 't'</li>
<li>Replace false for 'f'</li>
<li>Add <code>BEGIN;</code> as first line and <code>END;</code> as last line</li>
</ul>
</li>
<li>Recreate an empty development database.
<code>bundle exec rake db:migrate</code></li>
<li>Import the dump.
<code>bash
sqlite3 db/development.sqlite3
sqlite&gt; delete from schema_migrations;
sqlite&gt; .read dump.sql
</code>

<h2>Longer story a.k.a please explain a little more.</h2></li>
</ol>


<p>So basically you can do the following 4 major steps to convert the PostgreSQL database into a SQLite database.</p>

<h3>1. Generate a SQL dump</h3>

<p>First we have to create a sql dump on the production server. I use the following command that results in a <code>dump.sql</code> file in the current folder:</p>

<p><code>bash
pg_dump --data-only --inserts YOUR_DB_NAME &gt; dump.sql
</code></p>

<p>I use the <code>--data-only</code> option, so it doesn't generate the schema. Converting the pg_dump generate schema to a valid SQLite schema gave me a lot of difficulties so I chose to generate the schema with the <code>rake db</code> task (we'll discuss this in the next step).</p>

<p>After you created the dump, you have to download/transfer/mail/etc. that file so you have local access to it.</p>

<h4>Trick: Got ssh access?</h4>

<p>If you have ssh access, you can also run the following command, which will output the file directly on you local drive</p>

<p><code>bash
ssh -C username@hostname.com pg_dump --data-only --inserts YOUR_DB_NAME &gt; dump.sql
</code></p>

<h3>2. Modify the dump.sql</h3>

<p>There are a few manual find/replace and delete action's you have to perform on the <code>dump.sql</code> file by hand.</p>

<h4>2.1 Remove the <code>SET</code> statements at the top</h4>

<p>You will see some statements at the top of the file like <code>SET statement_timeout = 0;</code> and <code>SET client_encoding = 'SQL_ASCII';</code> etc. Remove all of these lines that start with <code>SET</code>, because SQLite doesn't use these.</p>

<h4>2.2 Remove the setval sequence queries</h4>

<p>Under the <code>SET</code> queries you'll see some queries to set the correct sequence for auto incrementing the id's. SQLite doesn't keep these value's in a catalog and must be removed to prevent errors.</p>

<p>Remove all the line's that look like <code>SELECT pg_catalog.setval('MY_OBJECT_id_seq', 10, true);</code></p>

<h4>2.3 Replace true => 't' and false => 'f'</h4>

<p>The <code>pg_dump</code> generate's <code>true</code> and <code>false</code> as value's for the <code>INSERT INTO</code> statements. If we want to import these to SQLite we have to replace these to 't' and 'f'.</p>

<p><code>sql
-- These:
INSERT INTO table_name VALUES (1, true, false);
-- Should be replace to:
INSERT INTO table_name VALUES (1, 't', 'f');
</code></p>

<h4>2.4 Transactions. Make it fast!</h4>

<p>The first time I imported the dump (that was 2 mb) it took like 12 minutes to complete! After some googling I found out that SQLite's default behavior is putting each statement into a transaction, which seems to be the time waster (after the fix it toke 12 seconds).</p>

<p>To prevent this behavior you can run the script within 1 transaction by specifying <code>BEGIN;</code> at the top of the <code>dump.sql</code> and <code>END;</code> at the end of the file.</p>

<p>So you would have:</p>

<p><code>sql
BEGIN;
-- a lot of INSERT INTO statments
END;
</code></p>

<h3>3. Recreate the development database</h3>

<p>So now we have fetched the production data from the PostgreSQL database, we need to recreate the <code>development.sqlite3</code> database.</p>

<p>Make a backup and run the migration task</p>

<p><code>bash
mv db/development.sqlite3 db/development.backup.sqlite3
bundle exec rake db:migrate
</code></p>

<h4>Side note when migrating</h4>

<p>You must run the migration <strong>until</strong> the migrated version that is active on the production database. If not, you could have the situation where you have dropped a column and can't import the dump because the data depends on that column.</p>

<p>Check the <code>dump.sql</code> for the latest version number in the <code>schema_migrations</code> table and migrate to that version.</p>

<p>For example for the version <code>20121701120000</code> you would do:</p>

<p><code>bash
bundle exec rake db:migrate VERSION=20121701120000
</code></p>

<h3>4. Import the dump</h3>

<p>The final step is importing the dump file. To do this we have to execute the following command within a terminal:</p>

<p><code>bash
sqlite3 db/development.sqlite3
sqlite&gt; delete from schema_migrations;
sqlite&gt; .read dump.sql
</code></p>

<p>As you can see we first remove the records from the <code>schema_migrations</code> table, because these are also included in the <code>dump.sql</code>. Of course you could also remove the lines from the file, but I prefer this way.</p>

<p>The <code>.read</code> command just execute's all the lines within the specified file.</p>

<h2>Result</h2>

<p>And that's it! You now have a stuffed <code>development.sqlite3</code> database with all the production data out of the PostgreSQL database.</p>
]]></content>
  </entry>
  
</feed>
