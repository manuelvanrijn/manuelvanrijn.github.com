<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: code | Manuel van Rijn]]></title>
  <link href="http://manuel.manuelles.nl/blog/categories/code/atom.xml" rel="self"/>
  <link href="http://manuel.manuelles.nl/"/>
  <updated>2012-01-20T18:14:42+01:00</updated>
  <id>http://manuel.manuelles.nl/</id>
  <author>
    <name><![CDATA[Manuel van Rijn]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[“Rake, pull me that DB!”]]></title>
    <link href="http://manuel.manuelles.nl/blog/2012/01/19/rake-pull-me-that-db/"/>
    <updated>2012-01-19T15:15:00+01:00</updated>
    <id>http://manuel.manuelles.nl/blog/2012/01/19/rake-pull-me-that-db</id>
    <content type="html"><![CDATA[<p>After writing my last article how to <a href="http://manuel.manuelles.nl/blog/2012/01/18/convert-postgresql-to-sqlite/" title="How to: Convert a PostgreSQL database to a SQLite database">Convert PostgreSQL to SQLite</a>, I was asked why this couldn't be automated?</p>

<p>So I started coding and managed to create a <a href="http://rake.rubyforge.org/" title="Rake -- Ruby Make">Rake</a> task that will do all of the steps I described in the article in just a few seconds!</p>

<!-- more -->


<h2>What will it do?</h2>

<ol>
<li>remove old dump and ssh the new dump to <code>tmp/dump.sql</code></li>
<li>converts the dumped SQL in to a valid format for SQLite</li>
<li>remembers the version number of the migration on the production db</li>
<li>backup, create and migrates the development SQLite to the version remembered</li>
<li>import the SQL</li>
<li>tell you all went well</li>
</ol>


<h2>Configuration</h2>

<p>To use the Rake task, you have to add 2 additional fields (<code>ssh_user</code> and <code>ssh_host</code>) to your <code>database.yml</code> file. These fields are used to create an ssh connection for retrieving the PostgreSQL dump.</p>

<p>Here's example of a modified <code>config/database.yml</code>:</p>

<p><div><script src='https://gist.github.com/1640429.js?file=database.yml'></script>
<noscript><pre><code>development:
  adapter: sqlite3
  database: db/development.sqlite3
  pool: 5
  timeout: 5000

production:
  ssh_user: root                  # &lt;-- add username for ssh
  ssh_host: productionserver.com  # &lt;-- add hostname for ssh
  adapter: postgresql
  host: localhost
  port: 5432
  username: db_user
  password: db_pass
  database: db_name
  schema_search_path: public
  encoding: utf8
  template: template0</code></pre></noscript></div>
</p>

<h2>Get the Rake file</h2>

<p>Put the following code into <code>libs/tasks/database.rake</code></p>

<p><div><script src='https://gist.github.com/1640429.js?file=database.rake'></script>
<noscript><pre><code>require 'fileutils'

namespace :db do
  desc 'pull the production PostgreSQL database into the development SQLite'
  task :pull do
    Rake::Task['db:download_pg_dump'].invoke
    Rake::Task['db:optimze_pg_dump_for_sqlite'].invoke
    Rake::Task['db:recreate_with_dump'].invoke
  end

  desc 'download the pg_dump content into tmp/dump.sql'
  task :download_pg_dump do
    config = Rails.application.config.database_configuration

    abort &quot;Missing production database config&quot; if config['production'].blank?

    dev  = config['development']
    prod = config['production']

    abort &quot;Development db is not sqlite3&quot; unless dev['adapter'] =~ /sqlite3/
    abort &quot;Production db is not postgresql&quot; unless prod['adapter'] =~ /postgresql/
    abort &quot;Missing ssh host&quot; if prod['ssh_host'].blank?
    abort &quot;Missing database name&quot; if prod['database'].blank?

    # remove the old one
    if File.exists?(pg_dump_file_path)
      File.delete(pg_dump_file_path)
    end

    cmd  = &quot;ssh -C &quot;
    cmd &lt;&lt; &quot;#{prod['ssh_user']}@&quot; if prod['ssh_user'].present?
    cmd &lt;&lt; &quot;#{prod['ssh_host']} &quot;
    cmd &lt;&lt; &quot;PGPASSWORD=#{prod['password']} &quot;
    cmd &lt;&lt; &quot;pg_dump --data-only --inserts &quot;
    cmd &lt;&lt; &quot;--username=#{prod['username']} #{prod['database']} &gt; &quot;
    cmd &lt;&lt; pg_dump_file_path

    system `#{cmd}`
  end

  desc 'remove unused statements and optimze sql for SQLite'
  task :optimze_pg_dump_for_sqlite do
    result = []
    lines = File.readlines(pg_dump_file_path)
    @version = 0
    lines.each do | line |
      next if line =~ /SELECT pg_catalog.setval/  # sequence value's
      next if line =~ /SET /                      # postgres specific config
      next if line =~ /--/                        # comment

      if line =~ /INSERT INTO schema_migrations/
        @version = line.match(/INSERT INTO schema_migrations VALUES \('([\d]*)/)[1]
      end

      # replace true and false for 't' and 'f'
      line.gsub!(&quot;true&quot;,&quot;'t'&quot;)
      line.gsub!(&quot;false&quot;,&quot;'f'&quot;)
      result &lt;&lt; line
    end

    File.open(pg_dump_file_path, &quot;w&quot;) do |f|
      # Add BEGIN and END so we add it to 1 transaction. Increase speed!
      f.puts(&quot;BEGIN;&quot;)
      result.each{|line| f.puts(line) unless line.blank?}
      f.puts(&quot;END;&quot;)
    end
  end

  desc 'backup development.sqlite3 and create a new one with the dumped data'
  task :recreate_with_dump do
    # sqlite so backup
    database = Rails.configuration.database_configuration['development']['database']
    database_path = File.expand_path(&quot;#{Rails.root}/#{database}&quot;)
    # remove old backup
    if File.exists?(database_path + '.backup')
      File.delete(database_path + '.backup')
    end
    # copy current for backup
    FileUtils.cp database_path, database_path + '.backup' if File.exists?(database_path)

    # dropping and re-creating db
    ENV['VERSION'] = @version
    Rake::Task['db:drop'].invoke
    Rake::Task[&quot;db:migrate&quot;].invoke

    puts &quot;migrated to version: #{@version}&quot;
    puts &quot;importing...&quot;
    # remove migration info
    system `sqlite3 #{database_path} &quot;delete from schema_migrations;&quot;`
    # import dump.sql
    system `sqlite3 #{database_path} &quot;.read #{pg_dump_file_path}&quot;`

    puts &quot;DONE!&quot;
    puts &quot;NOTE: you're now migrated to version #{@version}. Please run db:migrate to apply newer migrations&quot;
  end

  def pg_dump_file_path
    File.expand_path(&quot;#{Rails.root}/tmp/dump.sql&quot;)
  end
end</code></pre></noscript></div>
</p>

<h2>Usage</h2>

<p><code>
bundle exec rake db:pull
</code></p>

<h3>No SSH?</h3>

<p>If you want to skip the step where the rake tasks get's the dump using ssh, you have to copy the dump.sql into the tmp folder by yourself (note that the name <strong>must</strong> be <code>dump.sql</code>)</p>

<p>After you copied it, you should execute the following commands, to generate the development database with the dumped sql.</p>

<p><code>
bundle exec rake db:optimze_pg_dump_for_sqlite
bundle exec rake db:recreate_with_dump
</code></p>

<h3>Want to skip entering the ssh password every time?</h3>

<p>You could generate a public/private key pair with RSA and append that key to the production server so you don't have to enter the password over and over again to connect with ssh.</p>

<h4>1. Generate a public/private key pair with RSA</h4>

<p>First check if you haven't already generated a <code>id_rsa</code> file in your <code>$HOME/.shh</code> folder. If you already have a <code>id_rsa</code> file continue with step 2.</p>

<p>Run the following command on you local machine and accept the defaults.</p>

<p><code>
ssh-keygen -t rsa
</code></p>

<p>This command creates an RSA public/private key pair in your <code>$HOME/.ssh</code> directory. The private key is <code>~/.ssh/id_rsa</code> and the public key is <code>~/.ssh/id_rsa.pub</code></p>

<h4>2. Install public key on remote machine</h4>

<p>Now you can copy the public key to the remote machine by executing the following command:</p>

<p><code>
ssh-copy-id -i root@productionserver.com
</code></p>

<p>This command will ask you to enter the ssh password for the ssh user "root" for the hostname "productionserver.com".</p>

<p>After you've enter the password (for the last time) you can create a ssh connection without entering the password by executing:</p>

<p><code>
ssh root@productionserver.com
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Convert PostgreSQL to SQLite]]></title>
    <link href="http://manuel.manuelles.nl/blog/2012/01/18/convert-postgresql-to-sqlite/"/>
    <updated>2012-01-18T00:30:00+01:00</updated>
    <id>http://manuel.manuelles.nl/blog/2012/01/18/convert-postgresql-to-sqlite</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/posts/postgres-to-sqlite.png" width="220" height="220" title="Postgres to SQLite" ></p>

<p>Today I'd like to share the steps I take when I need to convert a <a href="http://www.postgresql.org/" title="PostgreSQL">PostgreSQL</a> database into a <a href="http://www.sqlite.org/" title="SQLite">SQLite</a> database.</p>

<p>Commonly I have to do this when a <a href="http://rubyonrails.org/" title="Ruby on Rails">Ruby on Rails</a> application is in production and I have to check some issues with the production data. In the production environment we usually use a PostgreSQL database and for developing I use a SQLite database, so we need some conversion.</p>

<!-- more -->


<h2>Short story a.k.a I know what I'm doing.</h2>

<ol>
<li>Create a dump of the PostgreSQL database.
<code>ssh -C username@hostname.com pg_dump --data-only --inserts YOUR_DB_NAME &gt; dump.sql</code></li>
<li>Remove/modify the dump.

<ul>
<li>Remove the lines starting with <code>SET</code></li>
<li>Remove the lines starting with <code>SELECT pg_catalog.setval</code></li>
<li>Replace true for 't'</li>
<li>Replace false for 'f'</li>
<li>Add <code>BEGIN;</code> as first line and <code>END;</code> as last line</li>
</ul>
</li>
<li>Recreate an empty development database.
<code>bundle exec rake db:migrate</code></li>
<li>Import the dump.
<code>bash
sqlite3 db/development.sqlite3
sqlite&gt; delete from schema_migrations;
sqlite&gt; .read dump.sql
</code>

<h2>Longer story a.k.a please explain a little more.</h2></li>
</ol>


<p>So basically you can do the following 4 major steps to convert the PostgreSQL database into a SQLite database.</p>

<h3>1. Generate a SQL dump</h3>

<p>First we have to create a sql dump on the production server. I use the following command that results in a <code>dump.sql</code> file in the current folder:</p>

<p><code>bash
pg_dump --data-only --inserts YOUR_DB_NAME &gt; dump.sql
</code></p>

<p>I use the <code>--data-only</code> option, so it doesn't generate the schema. Converting the pg_dump generate schema to a valid SQLite schema gave me a lot of difficulties so I chose to generate the schema with the <code>rake db</code> task (we'll discuss this in the next step).</p>

<p>After you created the dump, you have to download/transfer/mail/etc. that file so you have local access to it.</p>

<h4>Trick: Got ssh access?</h4>

<p>If you have ssh access, you can also run the following command, which will output the file directly on you local drive</p>

<p><code>bash
ssh -C username@hostname.com pg_dump --data-only --inserts YOUR_DB_NAME &gt; dump.sql
</code></p>

<h3>2. Modify the dump.sql</h3>

<p>There are a few manual find/replace and delete action's you have to perform on the <code>dump.sql</code> file by hand.</p>

<h4>2.1 Remove the <code>SET</code> statements at the top</h4>

<p>You will see some statements at the top of the file like <code>SET statement_timeout = 0;</code> and <code>SET client_encoding = 'SQL_ASCII';</code> etc. Remove all of these lines that start with <code>SET</code>, because SQLite doesn't use these.</p>

<h4>2.2 Remove the setval sequence queries</h4>

<p>Under the <code>SET</code> queries you'll see some queries to set the correct sequence for auto incrementing the id's. SQLite doesn't keep these value's in a catalog and must be removed to prevent errors.</p>

<p>Remove all the line's that look like <code>SELECT pg_catalog.setval('MY_OBJECT_id_seq', 10, true);</code></p>

<h4>2.3 Replace true => 't' and false => 'f'</h4>

<p>The <code>pg_dump</code> generate's <code>true</code> and <code>false</code> as value's for the <code>INSERT INTO</code> statements. If we want to import these to SQLite we have to replace these to 't' and 'f'.</p>

<p><code>sql
-- These:
INSERT INTO table_name VALUES (1, true, false);
-- Should be replace to:
INSERT INTO table_name VALUES (1, 't', 'f');
</code></p>

<h4>2.4 Transactions. Make it fast!</h4>

<p>The first time I imported the dump (that was 2 mb) it took like 12 minutes to complete! After some googling I found out that SQLite's default behavior is putting each statement into a transaction, which seems to be the time waster (after the fix it toke 12 seconds).</p>

<p>To prevent this behavior you can run the script within 1 transaction by specifying <code>BEGIN;</code> at the top of the <code>dump.sql</code> and <code>END;</code> at the end of the file.</p>

<p>So you would have:</p>

<p><code>sql
BEGIN;
-- a lot of INSERT INTO statments
END;
</code></p>

<h3>3. Recreate the development database</h3>

<p>So now we have fetched the production data from the PostgreSQL database, we need to recreate the <code>development.sqlite3</code> database.</p>

<p>Make a backup and run the migration task</p>

<p><code>bash
mv db/development.sqlite3 db/development.backup.sqlite3
bundle exec rake db:migrate
</code></p>

<h4>Side note when migrating</h4>

<p>You must run the migration <strong>until</strong> the migrated version that is active on the production database. If not, you could have the situation where you have dropped a column and can't import the dump because the data depends on that column.</p>

<p>Check the <code>dump.sql</code> for the latest version number in the <code>schema_migrations</code> table and migrate to that version.</p>

<p>For example for the version <code>20121701120000</code> you would do:</p>

<p><code>bash
bundle exec rake db:migrate VERSION=20121701120000
</code></p>

<h3>4. Import the dump</h3>

<p>The final step is importing the dump file. To do this we have to execute the following command within a terminal:</p>

<p><code>bash
sqlite3 db/development.sqlite3
sqlite&gt; delete from schema_migrations;
sqlite&gt; .read dump.sql
</code></p>

<p>As you can see we first remove the records from the <code>schema_migrations</code> table, because these are also included in the <code>dump.sql</code>. Of course you could also remove the lines from the file, but I prefer this way.</p>

<p>The <code>.read</code> command just execute's all the lines within the specified file.</p>

<h2>Result</h2>

<p>And that's it! You now have a stuffed <code>development.sqlite3</code> database with all the production data out of the PostgreSQL database.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Disable Rails callback]]></title>
    <link href="http://manuel.manuelles.nl/blog/2012/01/12/disable-rails-before-slash-after-callback/"/>
    <updated>2012-01-12T21:30:00+01:00</updated>
    <id>http://manuel.manuelles.nl/blog/2012/01/12/disable-rails-before-slash-after-callback</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/posts/skip-step.png" width="240" height="240" title="Skip Step" ></p>

<p>Today I've had some difficulties with a Rails migration, that took ages to complete. After some debugging I figured out that the issues was because of the <code>before_save</code> and <code>after_save</code> callbacks.</p>

<p>Of course we could remove the before and after save callbacks to speed up the process, but I don't like the idea of releasing a model that misses these behavior. I mean they're not there for no reason right?</p>

<!-- more -->


<p>After some googling I found a quick and easy way to disable the callbacks without modifying the model. Here's an simple example of a model class and a migration the disable the callbacks only within the migration.</p>

<h2>Code solution</h2>

<p>``` ruby app/models/some_model.rb
class SomeModel &lt; ActiveRecord::Base
  before_save :before_action
  after_save :after_action</p>

<p>  private</p>

<pre><code>def before_action
  # heavy calculation/queries
  puts "you shouldn't see this"
end

def after_action
  # another heavy calculation/queries
  puts "you shouldn't see this"
end
</code></pre>

<p>end
```</p>

<p>``` ruby db/migrations/20120112092136_update_some_model.rb
class UpdateSomeModel &lt; ActiveRecord::Migration
  def up</p>

<pre><code># disable the before_save
SomeModel.skip_callback(:save, :before, :before_action)
# disable the after_save
SomeModel.skip_callback(:save, :after, :after_action)

SomeModel.all.each do | obj |
  # .. modify obj ...

  obj.save
  # you shouldn't see the puts defined in the SomeModel before and after actions
end
</code></pre>

<p>  end</p>

<p>  def down
  end
end
```</p>

<h2>Supported callbacks</h2>

<p>In the above example I show only two rails callbacks. Here's a list of the supported callbacks you also can disable with it.</p>

<ul>
<li><code>:after_initialize</code></li>
<li><code>:after_find</code></li>
<li><code>:after_touch</code></li>
<li><code>:before_validation</code></li>
<li><code>:after_validation</code></li>
<li><code>:before_save</code></li>
<li><code>:around_save</code></li>
<li><code>:after_save</code></li>
<li><code>:before_create</code></li>
<li><code>:around_create</code></li>
<li><code>:after_create</code></li>
<li><code>:before_update</code></li>
<li><code>:around_update</code></li>
<li><code>:after_update</code></li>
<li><code>:before_destroy</code></li>
<li><code>:around_destroy</code></li>
<li><code>:after_destroy</code></li>
<li><code>:after_commit</code></li>
<li><code>:after_rollback</code></li>
</ul>


<p>Hope these could help you out some day =)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Shrinking your Git repository]]></title>
    <link href="http://manuel.manuelles.nl/blog/2011/12/22/shrinking-your-git-repository/"/>
    <updated>2011-12-22T15:01:00+01:00</updated>
    <id>http://manuel.manuelles.nl/blog/2011/12/22/shrinking-your-git-repository</id>
    <content type="html"><![CDATA[<p>In the past weeks I've looked into a problem that kept us from releasing to <a href="http://www.heroku.com/" title="Heroku">Heroku</a>, because the git repository was to large. In time the repository has grown to approximate <strong>180 Mb</strong>.</p>

<p><img class="right" src="/images/posts/shrink-mario.jpg" width="140" height="140" title="Shrink!" ></p>

<p>In the past we've made some decisions that we probably wouldn't take again. We for example, we decided to store the gem files in the vendor folder and having the rails code included in our repository. Our goal then was, that releasing the project with <a href="http://www.capify.org" title="Capistrano">Capistrano</a> would be easier and faster, because it didn't have to download all the gem's.</p>

<p>Anyway at this point we don't have the gem's stored anymore in the vendor folder. Since tools like <a href="http://beginrescueend.com/" title="Ruby version Manager">RVM</a> and <a href="https://github.com/sstephenson/rbenv/" title="rbenv">rbenv</a> we store these within the ruby/rails version of that specific project.</p>

<p>Still we have the problem that the repository contains files etc. we want to remove to shrink the size of it.</p>

<!-- more -->


<h2>Find large files from your git history</h2>

<p>First we have to track down what files are making our repository so large. I've found a perl script that scans your repository for files of a specific size. Here's the code:</p>

<p><div><script src='https://gist.github.com/1354502.js?file='></script>
<noscript><pre><code>#!/usr/bin/perl
use 5.008;
use strict;
use Memoize;

# usage:
# git-large-files 500k
# git-large-files 0.5m
# git-large-files 5b

sub usage { die &quot;usage: git-large-files &lt;size[b|k|m]&gt; [&lt;git-log arguments ...&gt;]\n&quot; }

@ARGV or usage();
my ( $max_size, $unit ) = ( shift =~ /^(\d+)([bkm]?)\z/ ) ? ( $1, $2 ) : usage();

my $exp = 10 * ( $unit eq 'b' ? 0 : $unit eq 'k' ? 1 : 2 );
my $cutoff = $max_size * 2**$exp;

sub walk_tree {
    my ( $tree, @path ) = @_;
    my @subtree;
    my @r;

    {
        open my $ls_tree, '-|', git =&gt; 'ls-tree' =&gt; -l =&gt; $tree
            or die &quot;Couldn't open pipe to git-ls-tree: $!\n&quot;;

        while ( &lt;$ls_tree&gt; ) {
            my ( $type, $sha1, $size, $name ) = /\A[0-7]{6} (\S+) (\S+) +(\S+)\t(.*)/;
            if ( $type eq 'tree' ) {
                push @subtree, [ $sha1, $name ];
            }
            elsif ( $type eq 'blob' and $size &gt;= $cutoff ) {
                push @r, [ $size, @path, $name ];
            }
        }
    }

    push @r, walk_tree( $_-&gt;[0], @path, $_-&gt;[1] )
        for @subtree;

    return @r;
}

memoize 'walk_tree';

open my $log, '-|', git =&gt; log =&gt; @ARGV, '--pretty=format:%T %h %cr'
    or die &quot;Couldn't open pipe to git-log: $!\n&quot;;

my %seen;
while ( &lt;$log&gt; ) {
    chomp;
    my ( $tree, $commit, $age ) = split &quot; &quot;, $_, 3;
    my $is_header_printed;
    for ( walk_tree( $tree ) ) {
        my ( $size, @path ) = @$_;
        my $path = join '/', @path;
        next if $seen{ $path }++;
        print &quot;$commit $age\n&quot; if not $is_header_printed++;
        print &quot;\t$size\t$path\n&quot;;
    }
}</code></pre></noscript></div>
</p>

<p>So I've placed this file within my repository and executed the below command to see all files, from all commits, that are bigger then <strong>500 Kb</strong></p>

<p><code>
perl git-large-files.pl 500k
</code></p>

<p>This give's you an output like:</p>

<p><code>
9794784 6 weeks ago
  609280  vendor/cache/builder-3.0.0.gem
  823808  vendor/cache/ffi-1.0.9.gem
  801792  vendor/cache/gherkin-2.4.21.gem
.... more ....
874451c 3 months ago
  609280  vendor/bundle/ruby/1.9.1/cache/builder-3.0.0.gem
  823808  vendor/bundle/ruby/1.9.1/cache/ffi-1.0.9.gem
  801792  vendor/bundle/ruby/1.9.1/cache/gherkin-2.4.21.gem
.... more ....
47ebdca 1 year, 1 month ago
  15467626  vendor/gems/webrat-0.7.1/vendor/selenium-server.jar
  6185324 vendor/rails/activerecord/examples/performance.sql
  14465482  log/development.log
</code></p>

<p>As you can see the following folders contain data that we don't need anymore and fills our repository with unused data:</p>

<ol>
<li>vendor/cache/*</li>
<li>vendor/bundle/*</li>
<li>vendor/rails/*</li>
<li>log/development.log</li>
</ol>


<h2>Removing the files from git</h2>

<p>To remove the folders specified above I used the commands specified by the <a href="http://help.github.com/remove-sensitive-data/" title="GitHub Help: Remove sensitive data">Remove sensitive data</a> post from GitHub Help</p>

<p>The only thing I changed was adding <code>-rf</code> to the <code>git rm</code> command to recursively force remove the files because I am dealing with multiple files/folders within the target folder.</p>

<h3>Rewrite history</h3>

<p>The final command I used was:</p>

<p><code>
git filter-branch -f --index-filter 'git rm -rf --cached --ignore-unmatch vendor/cache/* vendor/bundle/* vendor/rails/* log/development.log' --prune-empty -- --all
</code></p>

<p>Mind the <code>vendor/cache/* vendor/bundle/* vendor/rails/* log/development.log</code> part. You can provide multiple path's</p>

<p>When the command is finished, the history has been rewritten, but still the size of the repository hasn't changed at this point.</p>

<h3>Cleanup and reclaim space</h3>

<p>You have to execute the following commands to also remove the files from you local repository.</p>

<p><code>
rm -rf .git/refs/original/
git reflog expire --expire=now --all
git gc --aggressive --prune=now
</code></p>

<p>Now we can force push our repository so that others can enjoy our effort.</p>

<p><code>
git push origin master --force
</code></p>

<h2>The result (98,55% smaller)</h2>

<p>After following the above steps our repository was shrinked by <strong>98,55 %!</strong>. First the repository was 180 Mb and now it is <strong>2.6 Mb</strong></p>

<p>Ofcourse we had this numbers because there were alot of gem files within our repository that were updated frequently and pushed over and over again to the master branch.</p>

<p>I hope this post will help other's to track large files within there git repository and how they can remove them to shrink the size of there repostiories.</p>
]]></content>
  </entry>
  
</feed>
